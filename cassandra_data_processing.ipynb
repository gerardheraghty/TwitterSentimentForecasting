{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cfe45e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "[nltk_data] Downloading package stopwords to /home/hduser/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#importing the relevant packages\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import date_format\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "from pyspark.sql.functions import col, year,month, to_date, col, isnan, when, count, udf, trim, ltrim, rtrim, lower\n",
    "from pyspark.sql import Window\n",
    "import time\n",
    "from pyspark.sql.functions import to_timestamp\n",
    "import re\n",
    "\n",
    "import string\n",
    "\n",
    "#nltk related package/modules\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "\n",
    "#supressing the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc49c1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#may need to pip install nltk if not available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c53ad84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b279981f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.2.15:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#looking at the spark context, showing the connection to the spark cluster\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e68886f",
   "metadata": {},
   "source": [
    "## Section 1: Loading data directly from Cassandra database\n",
    "Using the cassandra connector, it is possible to load the data directy from Cassandra using the spark.read.format command in the below code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "edf48e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in file from cassandra cluster to pyspark dataframe\n",
    "project_tweets_df = spark.read.format(\"org.apache.spark.sql.cassandra\")\\\n",
    "                    .options(table=\"project_tweets\", keyspace=\"twitter_sentiment\").load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a9d5f7",
   "metadata": {},
   "source": [
    "Spark programming model has two types of operations: **Actions** and **Transformations**.<br>\n",
    "\n",
    "- **Transformations** are operations on RDDs, DataFrames, or Datasets that produce a new distributed dataset from an existing one. They are generally lazy, meaning they are not executed immediately but create a logical execution plan. These include functions such as withColumn, groupBy, filter, join etc. <br>\n",
    "\n",
    "- **Actions** are operations that trigger the execution of transformations and return a value to the driver program or write data to an external storage system. They are the operations that actually initiate the computation. <br>\n",
    "\n",
    "Both of these will be utilised in the below code, starting with the two Action operations .show() and .count() used immediately below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f6c821d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------+----------+--------------------+-----------+\n",
      "|   indx|                date|    flag|       ids|                text|       user|\n",
      "+-------+--------------------+--------+----------+--------------------+-----------+\n",
      "|1328206|Wed Jun 03 04:47:...|NO_QUERY|2015487701|hmmm i need to fi...|  xxlogannn|\n",
      "|  84049|Sun May 10 01:57:...|NO_QUERY|1753501222|2 stressed about ...|  SonyCandy|\n",
      "| 571099|Wed Jun 17 09:28:...|NO_QUERY|2208663921|And of course, pa...|   JMJ697MN|\n",
      "| 296315|Mon Jun 01 16:14:...|NO_QUERY|1997095180|Hmm... Everything...|sillygirlkc|\n",
      "| 761637|Tue Jun 23 10:20:...|NO_QUERY|2297349871|Oh gee i hate whe...|MLB_Roxanne|\n",
      "+-------+--------------------+--------+----------+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#displaying the first 5 rows of the data\n",
    "project_tweets_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "161861af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1599671"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_tweets_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8a9561",
   "metadata": {},
   "source": [
    "- Note that there are less than the total 1,600,000 records due to Cassandra not including duplicates when inserting tables into the database. Therefore any records with matching index (i.e indx) values will not be inserted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d2bcda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- indx: string (nullable = false)\n",
      " |-- date: string (nullable = true)\n",
      " |-- flag: string (nullable = true)\n",
      " |-- ids: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- user: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#taking a look at the data types\n",
    "project_tweets_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe6365c",
   "metadata": {},
   "source": [
    "## Section 2: cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d82ab7",
   "metadata": {},
   "source": [
    "### recasting string columns to longs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb8dafe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#casting to longs\n",
    "columns_to_integer = ['ids','indx']\n",
    "\n",
    "for col_name in columns_to_integer:\n",
    "    project_tweets_df = project_tweets_df.withColumn(col_name, col(col_name).cast('long'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113eeef7",
   "metadata": {},
   "source": [
    "### updating date column to a timestamp datatype to aid in analysis\n",
    "Need to timeParserPolicy to LEGACY to allow this casting as it is not supported in Spark version > 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e527d58c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[key: string, value: string]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set spark.sql.legacy.timeParserPolicy to LEGACY to restore the behavior before Spark 3.0.\n",
    "spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc2403fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string to timestamp and standardizing timezone to UTC\n",
    "project_tweets_df = project_tweets_df.withColumn(\"datetime\", \\\n",
    "                                                 to_timestamp(project_tweets_df[\"date\"],\\\n",
    "                                                              \"EEE MMM dd HH:mm:ss zzz yyyy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62d8b4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------+----------+--------------------+---------------+-------------------+\n",
      "|   indx|                date|    flag|       ids|                text|           user|           datetime|\n",
      "+-------+--------------------+--------+----------+--------------------+---------------+-------------------+\n",
      "| 738991|Sun Jun 21 06:57:...|NO_QUERY|2265614063|is church, celebr...|  buffsnowangel|2009-06-21 14:57:49|\n",
      "| 766924|Tue Jun 23 13:50:...|NO_QUERY|2300192267|//myspace message...|         jroyyy|2009-06-23 21:50:40|\n",
      "|1079727|Fri May 29 20:47:...|NO_QUERY|1968117864|Had a super long ...|marryme_invegas|2009-05-30 04:47:34|\n",
      "| 563328|Wed Jun 17 05:38:...|NO_QUERY|2205889101|@JustJenzz well i...|     keisyaarya|2009-06-17 13:38:06|\n",
      "|1406060|Sat Jun 06 09:03:...|NO_QUERY|2055291244|@NoBSGamers i jus...|        craven_|2009-06-06 17:03:00|\n",
      "| 731496|Sun Jun 21 01:57:...|NO_QUERY|2263839151|says this is gett...|   heidelicious|2009-06-21 09:57:58|\n",
      "| 469332|Mon Jun 15 03:10:...|NO_QUERY|2176187763|@antzpantz hahah ...|   crazybobbles|2009-06-15 11:10:00|\n",
      "|1493640|Sun Jun 07 16:04:...|NO_QUERY|2069547515|Lifesavers gummie...|      Brandalle|2009-06-08 00:04:42|\n",
      "|1511376|Mon Jun 15 00:02:...|NO_QUERY|2175082092|Thank you to the ...|            wjn|2009-06-15 08:02:27|\n",
      "| 810030|Tue Apr 07 06:59:...|NO_QUERY|1469643974|@BZB Thinking of ...|    The_Rooster|2009-04-07 14:59:52|\n",
      "| 536520|Tue Jun 16 16:03:...|NO_QUERY|2198420103|Ghost Whisperer :'( |    Courtney_17|2009-06-17 00:03:16|\n",
      "|1537976|Mon Jun 15 09:32:...|NO_QUERY|2179752184|had a nice day ou...|       Jealanny|2009-06-15 17:32:03|\n",
      "|1062490|Fri May 29 13:45:...|NO_QUERY|1964122585|@3JG is it the mo...|alildifferent15|2009-05-29 21:45:28|\n",
      "| 176180|Fri May 29 15:36:...|NO_QUERY|1965265589|@TheMrsH I saw an...|sickophantikmnd|2009-05-29 23:36:57|\n",
      "| 360539|Fri Jun 05 12:08:...|NO_QUERY|2046409859|@TracyReneeJones ...|        MzLaffy|2009-06-05 20:08:19|\n",
      "|1486966|Sun Jun 07 13:37:...|NO_QUERY|2068177539|I'm adding some g...| AngelaMarie292|2009-06-07 21:37:58|\n",
      "| 952602|Sun May 17 01:35:...|NO_QUERY|1824486382|@GuySebastian aww...|       kriztyle|2009-05-17 09:35:28|\n",
      "| 188864|Fri May 29 22:40:...|NO_QUERY|1968966661|http://twitpic.co...| kelliliddicoat|2009-05-30 06:40:13|\n",
      "|1198661|Sun May 31 16:35:...|NO_QUERY|1985183350|@mattgood Still a...|         kayzoe|2009-06-01 00:35:58|\n",
      "|1166155|Sun May 31 04:59:...|NO_QUERY|1979907535|on the train to g...|paris_corrupted|2009-05-31 12:59:04|\n",
      "+-------+--------------------+--------+----------+--------------------+---------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "project_tweets_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd5fd25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#updating the datetime \n",
    "#df = project_tweets_df.withColumn('date', to_date(project_tweets_df['datetime']))\n",
    "#df = df.sort('datetime',ascending=True)\n",
    "#distinct_dates_df = df.select('datetime').distinct().sort('datetime',ascending=True)#\n",
    "#distinct_dates_df.tail(10)\n",
    "#df.show(5)\n",
    "#distinct_dates_list = [row.datetime for row in distinct_dates_df.collect()]\n",
    "#distinct_dates_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32555835",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:=================================================>        (6 + 1) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|    flag|\n",
      "+--------+\n",
      "|NO_QUERY|\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "project_tweets_df.select(\"flag\").distinct().show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b984101",
   "metadata": {},
   "source": [
    "### Removing flag and date column as these are not required for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40d4e387",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_tweets_df = project_tweets_df.drop(*['date','flag','ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d10d4e",
   "metadata": {},
   "source": [
    "### Restructuring layout of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84a80f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_tweets_df = project_tweets_df.select([\"indx\",\"datetime\",\"user\",\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9fa476",
   "metadata": {},
   "source": [
    "### Sorting based on index value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c5b556fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorting based on indx\n",
    "project_tweets_df = project_tweets_df.sort('indx',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e05e393a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:=================================================>        (6 + 1) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+---------------+--------------------+\n",
      "|indx|           datetime|           user|                text|\n",
      "+----+-------------------+---------------+--------------------+\n",
      "|   0|2009-04-07 06:19:45|_TheSpecialOne_|@switchfoot http:...|\n",
      "|   1|2009-04-07 06:19:49|  scotthamilton|is upset that he ...|\n",
      "|   2|2009-04-07 06:19:53|       mattycus|@Kenichan I dived...|\n",
      "|   3|2009-04-07 06:19:57|        ElleCTF|my whole body fee...|\n",
      "|   4|2009-04-07 06:19:57|         Karoli|@nationwideclass ...|\n",
      "|   5|2009-04-07 06:20:00|       joy_wolf|@Kwesidei not the...|\n",
      "|   6|2009-04-07 06:20:03|        mybirch|         Need a hug |\n",
      "|   7|2009-04-07 06:20:03|           coZZ|@LOLTrish hey  lo...|\n",
      "|   8|2009-04-07 06:20:05|2Hood4Hollywood|@Tatiana_K nope t...|\n",
      "|   9|2009-04-07 06:20:09|        mimismo|@twittera que me ...|\n",
      "|  10|2009-04-07 06:20:16| erinx3leannexo|spring break in p...|\n",
      "|  11|2009-04-07 06:20:17|   pardonlauren|I just re-pierced...|\n",
      "|  12|2009-04-07 06:20:19|           TLeC|@caregiving I cou...|\n",
      "|  13|2009-04-07 06:20:19|robrobbierobert|@octolinz16 It it...|\n",
      "|  14|2009-04-07 06:20:20|    bayofwolves|@smarrison i woul...|\n",
      "|  15|2009-04-07 06:20:20|     HairByJess|@iamjazzyfizzle I...|\n",
      "|  16|2009-04-07 06:20:22| lovesongwriter|Hollis' death sce...|\n",
      "|  17|2009-04-07 06:20:25|       armotley|about to file taxes |\n",
      "|  18|2009-04-07 06:20:31|     starkissed|@LettyA ahh ive a...|\n",
      "|  19|2009-04-07 06:20:34|      gi_gi_bee|@FakerPattyPattz ...|\n",
      "+----+-------------------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "project_tweets_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3286b8e",
   "metadata": {},
   "source": [
    "### Checking for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "97582fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 23:=================================================>        (6 + 1) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+----+----+\n",
      "|indx|datetime|user|text|\n",
      "+----+--------+----+----+\n",
      "|   0|       0|   0|   0|\n",
      "+----+--------+----+----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "project_tweets_df.select([count(when(col(c).isNull(), c)).alias(c) for c in project_tweets_df.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7225264",
   "metadata": {},
   "source": [
    "### Checking for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "abc05278",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/13 09:20:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/13 09:20:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+----+----+\n",
      "|indx|datetime|user|text|\n",
      "+----+--------+----+----+\n",
      "+----+--------+----+----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 53:=============================>                            (2 + 2) / 4]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "project_tweets_df.exceptAll(project_tweets_df.dropDuplicates()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "79fe698c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 54:=================================================>        (6 + 1) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------+\n",
      "|text                                                                                                               |\n",
      "+-------------------------------------------------------------------------------------------------------------------+\n",
      "|@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D|\n",
      "|is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!    |\n",
      "|@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds                          |\n",
      "|my whole body feels itchy and like its on fire                                                                     |\n",
      "|@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.     |\n",
      "+-------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "project_tweets_df.select('text').show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38bfe5f",
   "metadata": {},
   "source": [
    "## Section 3: Text Processing\n",
    "\n",
    "This section will involve processing the text column in preparation for sentiment analysis. In order to perform sentiment analysis correctly, the text needs to be cleaned:\n",
    "- Twitter handles or usernames which add no value to the sentiment removed.\n",
    "- URLs or http/https links removed from the text.\n",
    "- Special characters such as #,\",@ etc. removed.\n",
    "- Stopwords (which are commonly appearing words in the english language such as \"the\", \"a\", \"an\" etc.) are removed.\n",
    "- Digits are removed.\n",
    "- All text made lower case.\n",
    "- Any leading or trailing whitespace removed.\n",
    "- Lemmetization is applied to break down each word in the text to its base root mode."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a35389",
   "metadata": {},
   "source": [
    "Each of these processing steps are conducted using **User Defined Functions (UDF)**, which are a feature of spark, to enable the defined function to applied to each row using the withColumn transformation function.<br>\n",
    "User Defined Functions (UDF) can be used to perform data transformation operations which are not already present in Pyspark built-in functionality\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb363d8",
   "metadata": {},
   "source": [
    "### Removing Username handles from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f90ae539",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining UDF for removing usernames\n",
    "def remove_usernames(text):\n",
    "    #regular expression for twitter username handles\n",
    "    regex = r'@([A-Za-z0-9_]+)'\n",
    "    #returning text without username handles by replacing them with an empty string value\n",
    "    return re.sub(regex, '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4760feb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_usernames_udf = udf(remove_usernames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8247c052",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_tweets_df = project_tweets_df.withColumn('text', remove_usernames_udf('text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "55996f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 58:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------+\n",
      "|text                                                                                                           |\n",
      "+---------------------------------------------------------------------------------------------------------------+\n",
      "| http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D       |\n",
      "|is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!|\n",
      "| I dived many times for the ball. Managed to save 50%  The rest go out of bounds                               |\n",
      "|my whole body feels itchy and like its on fire                                                                 |\n",
      "| no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.                 |\n",
      "+---------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "project_tweets_df.select('text').show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ab87876f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 60:=================================================>        (6 + 1) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|text                                                                                                                                    |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D                                |\n",
      "| sorry! bed time came here (GMT+1)   http://is.gd/fNge                                                                                  |\n",
      "|Broadband plan 'a massive broken promise' http://tinyurl.com/dcuc33 via www.diigo.com/~tautao Still waiting for broadband we are        |\n",
      "|Why won't you show my location?!   http://twitpic.com/2y2es                                                                             |\n",
      "|Strider is a sick little puppy  http://apps.facebook.com/dogbook/profile/view/5248435                                                   |\n",
      "| Body Of Missing Northern Calif. Girl Found: Police have found the remains of a missing Northern California girl .. http://tr.im/imji   |\n",
      "|Emily will be glad when Mommy is done training at her new job. She misses her.  http://apps.facebook.com/dogbook/profile/view/6176014   |\n",
      "|Crazy wind today = no birding  http://ff.im/1XTTi                                                                                       |\n",
      "|Check out my mug  http://www.erika-obscura.blogspot.com                                                                                 |\n",
      "|http://twitpic.com/2y2wr - according to my bro, our new puppy had a poo fight and was covered in poop  (picture stolen from him)        |\n",
      "|Su yin Huen tweeted I feel unbearable guilt. I made my staff cry  http://tinyurl.com/cw2l9t                                             |\n",
      "|getting annoyed easily today  &gt;&gt;&gt; biofuel proposal: getting annoyed easily today  &gt;&gt;&gt; biof.. http://tinyurl.com/ceprvs|\n",
      "|http://twitpic.com/2y2yi - I love you, Buck.                                                                                            |\n",
      "| https://www.mycomicshop.com/search?TID=395031 But all says not in stock                                                                |\n",
      "|Pepperoni rolls in L.A.?: I called Valentino's - they said that they had sausage rolls but no pepperoni rolls  http://tinyurl.com/cec5ka|\n",
      "|http://twitpic.com/2y34e - I wanna wear my Doc Martens out! Haven't worn them since December.                                           |\n",
      "|Duckling in famous children's book stolen from Boston's Public Garden - The Boston Globe http://tinyurl.com/dc2htx via  OH NO!!         |\n",
      "|http://twitpic.com/2y36e - cant see the flowers falling  i dont have a camera, just my cellphone                                        |\n",
      "|http://is.gd/r8Zf,  http://is.gd/r8Zy, and  http://is.gd/r8ZG - test footage with my girlfriend (in HD) The dark one is underxposed     |\n",
      "|Fraking app store is pissing me off   http://tinyurl.com/c4ooho                                                                         |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "project_tweets_df.filter(project_tweets_df.text.like(\"%http%\")).select('text').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28804753",
   "metadata": {},
   "source": [
    "### Removing urls within the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bbe9e658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_URL(text):\n",
    "    return re.sub(r\"http\\S+\", \"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c75771f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_URL_udf = udf(remove_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "48b7c6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_tweets_df = project_tweets_df.withColumn('text', remove_URL_udf('text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "268b6617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 64:=================================================>        (6 + 1) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------+\n",
      "|text                                                                                                           |\n",
      "+---------------------------------------------------------------------------------------------------------------+\n",
      "|  - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D                               |\n",
      "|is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!|\n",
      "| I dived many times for the ball. Managed to save 50%  The rest go out of bounds                               |\n",
      "|my whole body feels itchy and like its on fire                                                                 |\n",
      "| no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.                 |\n",
      "+---------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "project_tweets_df.select('text').show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "caf2fd23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 68:=================================================>        (6 + 1) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|text|\n",
      "+----+\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "project_tweets_df.filter(project_tweets_df.text.like(\"%http://%\")).select('text').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52351d9b",
   "metadata": {},
   "source": [
    "### Removing special characters (i.e punctuation, hashtags etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d9746f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 70:=================================================>        (6 + 1) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+---------------+--------------------+\n",
      "|indx|           datetime|           user|                text|\n",
      "+----+-------------------+---------------+--------------------+\n",
      "|   0|2009-04-07 06:19:45|_TheSpecialOne_|  - Awww, that's ...|\n",
      "|   1|2009-04-07 06:19:49|  scotthamilton|is upset that he ...|\n",
      "|   2|2009-04-07 06:19:53|       mattycus| I dived many tim...|\n",
      "|   3|2009-04-07 06:19:57|        ElleCTF|my whole body fee...|\n",
      "|   4|2009-04-07 06:19:57|         Karoli| no, it's not beh...|\n",
      "+----+-------------------+---------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "project_tweets_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "86207b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "48867fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    #defining regex to only include characters, digits or whitespace\n",
    "    char =r'[^a-zA-Z0-9\\s]'\n",
    "    return re.sub(char, \"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "90978de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_punctuation_udf = udf(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "534d1a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_tweets_df = project_tweets_df.withColumn('text', remove_punctuation_udf('text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "688b29c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 74:=================================================>        (6 + 1) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------+\n",
      "|text                                                                                                     |\n",
      "+---------------------------------------------------------------------------------------------------------+\n",
      "|   Awww thats a bummer  You shoulda got David Carr of Third Day to do it D                               |\n",
      "|is upset that he cant update his Facebook by texting it and might cry as a result  School today also Blah|\n",
      "| I dived many times for the ball Managed to save 50  The rest go out of bounds                           |\n",
      "|my whole body feels itchy and like its on fire                                                           |\n",
      "| no its not behaving at all im mad why am i here because I cant see you all over there                   |\n",
      "| not the whole crew                                                                                      |\n",
      "|Need a hug                                                                                               |\n",
      "| hey  long time no see Yes Rains a bit only a bit  LOL  Im fine thanks  hows you                         |\n",
      "| nope they didnt have it                                                                                 |\n",
      "| que me muera                                                                                            |\n",
      "|spring break in plain city its snowing                                                                   |\n",
      "|I just repierced my ears                                                                                 |\n",
      "| I couldnt bear to watch it  And I thought the UA loss was embarrassing                                  |\n",
      "| It it counts idk why I did either you never talk to me anymore                                          |\n",
      "| i wouldve been the first but i didnt have a gun    not really though zac snyders just a doucheclown     |\n",
      "| I wish I got to watch it with you I miss you and   how was the premiere                                 |\n",
      "|Hollis death scene will hurt me severely to watch on film  wry is directors cut not out now              |\n",
      "|about to file taxes                                                                                      |\n",
      "| ahh ive always wanted to see rent  love the soundtrack                                                  |\n",
      "| Oh dear Were you drinking out of the forgotten table drinks                                             |\n",
      "+---------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "project_tweets_df.select('text').show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcda533",
   "metadata": {},
   "source": [
    "### Removing digits from the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "00b0d617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove digits from the text column\n",
    "project_tweets_df = project_tweets_df.withColumn(\"text\", regexp_replace(\"text\", \"[0-9]\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fb758a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 78:=================================================>        (6 + 1) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------+\n",
      "|text                                                                                                     |\n",
      "+---------------------------------------------------------------------------------------------------------+\n",
      "|   Awww thats a bummer  You shoulda got David Carr of Third Day to do it D                               |\n",
      "|is upset that he cant update his Facebook by texting it and might cry as a result  School today also Blah|\n",
      "| I dived many times for the ball Managed to save   The rest go out of bounds                             |\n",
      "|my whole body feels itchy and like its on fire                                                           |\n",
      "| no its not behaving at all im mad why am i here because I cant see you all over there                   |\n",
      "| not the whole crew                                                                                      |\n",
      "|Need a hug                                                                                               |\n",
      "| hey  long time no see Yes Rains a bit only a bit  LOL  Im fine thanks  hows you                         |\n",
      "| nope they didnt have it                                                                                 |\n",
      "| que me muera                                                                                            |\n",
      "|spring break in plain city its snowing                                                                   |\n",
      "|I just repierced my ears                                                                                 |\n",
      "| I couldnt bear to watch it  And I thought the UA loss was embarrassing                                  |\n",
      "| It it counts idk why I did either you never talk to me anymore                                          |\n",
      "| i wouldve been the first but i didnt have a gun    not really though zac snyders just a doucheclown     |\n",
      "| I wish I got to watch it with you I miss you and   how was the premiere                                 |\n",
      "|Hollis death scene will hurt me severely to watch on film  wry is directors cut not out now              |\n",
      "|about to file taxes                                                                                      |\n",
      "| ahh ive always wanted to see rent  love the soundtrack                                                  |\n",
      "| Oh dear Were you drinking out of the forgotten table drinks                                             |\n",
      "+---------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "project_tweets_df.select('text').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ac2306",
   "metadata": {},
   "source": [
    "### Removing leading and trailing whitespace from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b87e2593",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 82:=================================================>        (6 + 1) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------+\n",
      "|text                                                                                                     |\n",
      "+---------------------------------------------------------------------------------------------------------+\n",
      "|Awww thats a bummer  You shoulda got David Carr of Third Day to do it D                                  |\n",
      "|is upset that he cant update his Facebook by texting it and might cry as a result  School today also Blah|\n",
      "|I dived many times for the ball Managed to save   The rest go out of bounds                              |\n",
      "|my whole body feels itchy and like its on fire                                                           |\n",
      "|no its not behaving at all im mad why am i here because I cant see you all over there                    |\n",
      "|not the whole crew                                                                                       |\n",
      "|Need a hug                                                                                               |\n",
      "|hey  long time no see Yes Rains a bit only a bit  LOL  Im fine thanks  hows you                          |\n",
      "|nope they didnt have it                                                                                  |\n",
      "|que me muera                                                                                             |\n",
      "|spring break in plain city its snowing                                                                   |\n",
      "|I just repierced my ears                                                                                 |\n",
      "|I couldnt bear to watch it  And I thought the UA loss was embarrassing                                   |\n",
      "|It it counts idk why I did either you never talk to me anymore                                           |\n",
      "|i wouldve been the first but i didnt have a gun    not really though zac snyders just a doucheclown      |\n",
      "|I wish I got to watch it with you I miss you and   how was the premiere                                  |\n",
      "|Hollis death scene will hurt me severely to watch on film  wry is directors cut not out now              |\n",
      "|about to file taxes                                                                                      |\n",
      "|ahh ive always wanted to see rent  love the soundtrack                                                   |\n",
      "|Oh dear Were you drinking out of the forgotten table drinks                                              |\n",
      "+---------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#can use the trim, ltrim and rtrim to remove the white space\n",
    "project_tweets_df = project_tweets_df.withColumn('text', trim('text'))\n",
    "project_tweets_df = project_tweets_df.withColumn('text', ltrim('text'))\n",
    "project_tweets_df = project_tweets_df.withColumn('text', rtrim('text'))\n",
    "\n",
    "\n",
    "project_tweets_df.select('text').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0354c089",
   "metadata": {},
   "source": [
    "### Making lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0e5e7b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 86:=================================================>        (6 + 1) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------+\n",
      "|text                                                                                                     |\n",
      "+---------------------------------------------------------------------------------------------------------+\n",
      "|awww thats a bummer  you shoulda got david carr of third day to do it d                                  |\n",
      "|is upset that he cant update his facebook by texting it and might cry as a result  school today also blah|\n",
      "|i dived many times for the ball managed to save   the rest go out of bounds                              |\n",
      "|my whole body feels itchy and like its on fire                                                           |\n",
      "|no its not behaving at all im mad why am i here because i cant see you all over there                    |\n",
      "|not the whole crew                                                                                       |\n",
      "|need a hug                                                                                               |\n",
      "|hey  long time no see yes rains a bit only a bit  lol  im fine thanks  hows you                          |\n",
      "|nope they didnt have it                                                                                  |\n",
      "|que me muera                                                                                             |\n",
      "|spring break in plain city its snowing                                                                   |\n",
      "|i just repierced my ears                                                                                 |\n",
      "|i couldnt bear to watch it  and i thought the ua loss was embarrassing                                   |\n",
      "|it it counts idk why i did either you never talk to me anymore                                           |\n",
      "|i wouldve been the first but i didnt have a gun    not really though zac snyders just a doucheclown      |\n",
      "|i wish i got to watch it with you i miss you and   how was the premiere                                  |\n",
      "|hollis death scene will hurt me severely to watch on film  wry is directors cut not out now              |\n",
      "|about to file taxes                                                                                      |\n",
      "|ahh ive always wanted to see rent  love the soundtrack                                                   |\n",
      "|oh dear were you drinking out of the forgotten table drinks                                              |\n",
      "+---------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "project_tweets_df = project_tweets_df.withColumn('text', lower('text'))\n",
    "\n",
    "project_tweets_df.select('text').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2780677",
   "metadata": {},
   "source": [
    "### Can drop the user column as this wont be required for sentiment forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "916e4028",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_tweets_df = project_tweets_df.drop('user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8f2d6e14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 90:=================================================>        (6 + 1) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+--------------------+\n",
      "|indx|           datetime|                text|\n",
      "+----+-------------------+--------------------+\n",
      "|   0|2009-04-07 06:19:45|awww thats a bumm...|\n",
      "|   1|2009-04-07 06:19:49|is upset that he ...|\n",
      "|   2|2009-04-07 06:19:53|i dived many time...|\n",
      "|   3|2009-04-07 06:19:57|my whole body fee...|\n",
      "|   4|2009-04-07 06:19:57|no its not behavi...|\n",
      "|   5|2009-04-07 06:20:00|  not the whole crew|\n",
      "|   6|2009-04-07 06:20:03|          need a hug|\n",
      "|   7|2009-04-07 06:20:03|hey  long time no...|\n",
      "|   8|2009-04-07 06:20:05|nope they didnt h...|\n",
      "|   9|2009-04-07 06:20:09|        que me muera|\n",
      "|  10|2009-04-07 06:20:16|spring break in p...|\n",
      "|  11|2009-04-07 06:20:17|i just repierced ...|\n",
      "|  12|2009-04-07 06:20:19|i couldnt bear to...|\n",
      "|  13|2009-04-07 06:20:19|it it counts idk ...|\n",
      "|  14|2009-04-07 06:20:20|i wouldve been th...|\n",
      "|  15|2009-04-07 06:20:20|i wish i got to w...|\n",
      "|  16|2009-04-07 06:20:22|hollis death scen...|\n",
      "|  17|2009-04-07 06:20:25| about to file taxes|\n",
      "|  18|2009-04-07 06:20:31|ahh ive always wa...|\n",
      "|  19|2009-04-07 06:20:34|oh dear were you ...|\n",
      "+----+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "project_tweets_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92925a5",
   "metadata": {},
   "source": [
    "### Removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9a04d243",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a1a79052",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing the stop words\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    return ' '.join([word for word in text.split() if word not in stop_words])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "89162046",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_stop_words_udf = udf(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a4303ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_tweets_df = project_tweets_df.withColumn('text', remove_stop_words_udf(col('text')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "29b00f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 94:=================================================>        (6 + 1) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------+\n",
      "|text                                                                      |\n",
      "+--------------------------------------------------------------------------+\n",
      "|awww thats bummer shoulda got david carr third day                        |\n",
      "|upset cant update facebook texting might cry result school today also blah|\n",
      "|dived many times ball managed save rest go bounds                         |\n",
      "|whole body feels itchy like fire                                          |\n",
      "|behaving im mad cant see                                                  |\n",
      "|whole crew                                                                |\n",
      "|need hug                                                                  |\n",
      "|hey long time see yes rains bit bit lol im fine thanks hows               |\n",
      "|nope didnt                                                                |\n",
      "|que muera                                                                 |\n",
      "|spring break plain city snowing                                           |\n",
      "|repierced ears                                                            |\n",
      "|couldnt bear watch thought ua loss embarrassing                           |\n",
      "|counts idk either never talk anymore                                      |\n",
      "|wouldve first didnt gun really though zac snyders doucheclown             |\n",
      "|wish got watch miss premiere                                              |\n",
      "|hollis death scene hurt severely watch film wry directors cut             |\n",
      "|file taxes                                                                |\n",
      "|ahh ive always wanted see rent love soundtrack                            |\n",
      "|oh dear drinking forgotten table drinks                                   |\n",
      "+--------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "project_tweets_df.select('text').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f40c19",
   "metadata": {},
   "source": [
    "### applying lemmatization to the text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "447471a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e095ff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1088f0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "giving : giving\n",
      "rocks : rock\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer() \n",
    " \n",
    "print(\"giving :\", lemmatizer.lemmatize(\"giving\")) \n",
    "print(\"rocks :\", lemmatizer.lemmatize(\"rocks\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "02cdbbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#firstly need to tokenize the words to allow each word to be lemmatized\n",
    "def tokenize_text(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "tokenize_text_udf = udf(tokenize_text, ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "583aae5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_tweets_df = project_tweets_df.withColumn(\"text\", tokenize_text_udf(col(\"text\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7d06df38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining udf to lemmatize the text using the WordNetLemmatizer instantiated above\n",
    "def lemmatize_text(words):\n",
    "    return [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "lemmatize_text_udf = udf(lemmatize_text, ArrayType(StringType()))\n",
    "\n",
    "project_tweets_df = project_tweets_df.withColumn(\"text\", lemmatize_text_udf(col(\"text\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0998f322",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finally need to join the tokens back together \n",
    "def join_text(words):\n",
    "    return \" \".join(words)\n",
    "\n",
    "join_text_udf = udf(join_text, StringType())\n",
    "project_tweets_df = project_tweets_df.withColumn(\"text\", join_text_udf(col(\"text\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b86fda11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "[Stage 100:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------+\n",
      "|text                                                                      |\n",
      "+--------------------------------------------------------------------------+\n",
      "|awww thats bummer shoulda got david carr third day                        |\n",
      "|upset cant update facebook texting might cry result school today also blah|\n",
      "|dived many time ball managed save rest go bound                           |\n",
      "|whole body feel itchy like fire                                           |\n",
      "|behaving im mad cant see                                                  |\n",
      "|whole crew                                                                |\n",
      "|need hug                                                                  |\n",
      "|hey long time see yes rain bit bit lol im fine thanks hows                |\n",
      "|nope didnt                                                                |\n",
      "|que muera                                                                 |\n",
      "|spring break plain city snowing                                           |\n",
      "|repierced ear                                                             |\n",
      "|couldnt bear watch thought ua loss embarrassing                           |\n",
      "|count idk either never talk anymore                                       |\n",
      "|wouldve first didnt gun really though zac snyders doucheclown             |\n",
      "|wish got watch miss premiere                                              |\n",
      "|hollis death scene hurt severely watch film wry director cut              |\n",
      "|file tax                                                                  |\n",
      "|ahh ive always wanted see rent love soundtrack                            |\n",
      "|oh dear drinking forgotten table drink                                    |\n",
      "|day didnt get much done                                                   |\n",
      "|one friend called asked meet mid valley todaybut ive time sigh            |\n",
      "|baked cake ated                                                           |\n",
      "|week going hoped                                                          |\n",
      "|blagh class tomorrow                                                      |\n",
      "|hate call wake people                                                     |\n",
      "|going cry sleep watching marley                                           |\n",
      "|im sad misslilly                                                          |\n",
      "|ooooh lol leslie ok wont leslie wont get mad                              |\n",
      "|meh almost lover exception track get depressed every time                 |\n",
      "+--------------------------------------------------------------------------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "project_tweets_df.select('text').show(30, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bff7986",
   "metadata": {},
   "source": [
    "### checking for empty string values after filtering done\n",
    "-These would have arisen from where the text only contained usernames or links which were removed leading to empty strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fd0d2adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7515"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_tweets_df.filter(project_tweets_df['text']=='').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "283680f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_tweets_df = project_tweets_df.filter(project_tweets_df[\"text\"]!='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "84111774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_tweets_df.filter(project_tweets_df['text']=='').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731897df",
   "metadata": {},
   "source": [
    "### getting the number of tweets per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a7ac572b",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_tweets_df = project_tweets_df.withColumn(\"date\", date_format(col(\"datetime\"), \"yyyy-MM-dd\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1d9dc383",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 78:=================================================>        (6 + 1) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|      date| count|\n",
      "+----------+------+\n",
      "|2009-06-23| 18447|\n",
      "|2009-04-18| 16073|\n",
      "|2009-05-04| 29672|\n",
      "|2009-06-20| 45448|\n",
      "|2009-05-27| 11554|\n",
      "|2009-04-19| 33522|\n",
      "|2009-05-25|   168|\n",
      "|2009-06-18| 43077|\n",
      "|2009-05-29| 55588|\n",
      "|2009-06-04|  4612|\n",
      "|2009-04-20| 18360|\n",
      "|2009-06-03| 60970|\n",
      "|2009-04-07| 20568|\n",
      "|2009-04-21| 11067|\n",
      "|2009-05-22| 40964|\n",
      "|2009-06-22|  6480|\n",
      "|2009-05-03| 24920|\n",
      "|2009-06-17| 43818|\n",
      "|2009-06-21| 32531|\n",
      "|2009-06-06|103495|\n",
      "+----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tweets_by_date = project_tweets_df.groupBy('date').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7297cf",
   "metadata": {},
   "source": [
    "## Section 4: Saving back to Cassandra database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2a1b55fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 107:================================================>        (6 + 1) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+--------------------+\n",
      "|indx|           datetime|                text|\n",
      "+----+-------------------+--------------------+\n",
      "|   0|2009-04-07 06:19:45|awww thats bummer...|\n",
      "|   1|2009-04-07 06:19:49|upset cant update...|\n",
      "|   2|2009-04-07 06:19:53|dived many time b...|\n",
      "|   3|2009-04-07 06:19:57|whole body feel i...|\n",
      "|   4|2009-04-07 06:19:57|behaving im mad c...|\n",
      "|   5|2009-04-07 06:20:00|          whole crew|\n",
      "|   6|2009-04-07 06:20:03|            need hug|\n",
      "|   7|2009-04-07 06:20:03|hey long time see...|\n",
      "|   8|2009-04-07 06:20:05|          nope didnt|\n",
      "|   9|2009-04-07 06:20:09|           que muera|\n",
      "|  10|2009-04-07 06:20:16|spring break plai...|\n",
      "|  11|2009-04-07 06:20:17|       repierced ear|\n",
      "|  12|2009-04-07 06:20:19|couldnt bear watc...|\n",
      "|  13|2009-04-07 06:20:19|count idk either ...|\n",
      "|  14|2009-04-07 06:20:20|wouldve first did...|\n",
      "|  15|2009-04-07 06:20:20|wish got watch mi...|\n",
      "|  16|2009-04-07 06:20:22|hollis death scen...|\n",
      "|  17|2009-04-07 06:20:25|            file tax|\n",
      "|  18|2009-04-07 06:20:31|ahh ive always wa...|\n",
      "|  19|2009-04-07 06:20:34|oh dear drinking ...|\n",
      "+----+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "project_tweets_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "73ea2230",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_tweets_df = project_tweets_df.drop('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c20e1a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- indx: long (nullable = true)\n",
      " |-- datetime: timestamp (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "project_tweets_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cba165ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to cassandra\n",
    "project_tweets_df.write.format(\"org.apache.spark.sql.cassandra\").options(table=\"project_tweets_processed\", keyspace=\"twitter_sentiment\").mode('append').save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b6eaf711",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to local\n",
    "project_tweets_df.write.format('csv').save('file:///home/hduser/Desktop/CA2/processed_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0088f26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#project_tweets_df_new.write\\\n",
    "#    .format(\"org.apache.spark.sql.cassandra\")\\\n",
    "#    .options(table=\"project_tweets\", keyspace=\"twitter_sentiment\")\\\n",
    "#    .mode('append')\\\n",
    "#    .option(\"spark.cassandra.connection.host\",\"127.0.0.1\")\\\n",
    "#    .option(\"spark.cassandra.connection.port\", \"9042\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a6e2b319",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saves to HDFS\n",
    "#project_tweets_df.write.csv('processed_tweets.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
